server:
  port: 8080

spring:
  application:
    name: llm-friend-chatbot
  ai:
    ollama:
      chat:
        # model: mistral:7b-instruct-v0.3-q8_0
        #model: deepseek-r1:14b
        model: llama3.1:8b
        # model: llama3.2:3b
      embedding:
        model: nomic-embed-text
    vectorstore:
      qdrant:
        host: localhost
        port: 6334
        collection-name: vector_store
        initialize-schema: true
        dimension: 768
  docker:
    compose:
      readiness:
        timeout: 5m
      wait:
        log-patterns:
          qdrant: "running"
      # lifecycle-management: start_only
de:
  sven:
    bayer:
      llm:
        friend:
          chatbot:
            llmName: Lumi
            maxDetailConversationMessagesHistory: 6
            maxConversationMessageHistory: 16
            maxSummarizationLength: 30
